---
title: "HW5: Markdown file"
author: "Kevin Liu"
date: "2023-11-12"
output: github_document
---

```{r include = FALSE}
library(tidyverse)
library(rvest)
```

# Problem 1

```{r }
raw_homicide_data =
  read_csv("./data/homicide-data.csv") |> 
  janitor::clean_names()
```

__Describe the raw data__

* There are `r nrow(raw_homicide_data)` rows and `r ncol(raw_homicide_data)` variables in the raw dataset.
* The 11 variables are "uid", "reported_date", "victim_last", "victim_first", "victim_race", "victim_age", "victim_sex", "city", "state", "lat", and "lon".
  * Respectively their variable types: chr, num, chr, chr, chr, chr, chr, chr, chr, num, num, and chr. 
  * The variables include full name of victim, their race, age, sex, the city and state and the coordinates of the homicide report and the date.

__Create a `city_state` variable__

```{r}
raw_homicide_data = 
  raw_homicide_data |> 
  
  #Create variable "city_state" which is a concatenation of city + state separated by , .
  mutate(city_state = paste(city, state, sep = ", "))
```

__Summarize__ 

...within cities to obtain the total number of homicides and the number of unsolved homicides.

```{r}
sum_homicides =
  raw_homicide_data |> 
  
  #Group by city_state 
  group_by(city_state) |> 
  
  #Summarize total_homicides as # of data inputs in each city and num_unsolved the # of data with "Closed without arrest" and "Open/No arrest" as the string value for disposition
  summarize(total_homicides = n(), num_unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))) 

head(sum_homicides, 10)
```

__For City of Baltimore, MD...__

...use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r}
#Extract Baltimore_MD data from the summarized data aobve
baltimore_prop = 
  sum_homicides |> 
  filter(city_state == "Baltimore, MD")

#Extract the number of unsolved and total homicides from baltimore dataset
balt_unsolved = baltimore_prop$num_unsolved
balt_total = baltimore_prop$total_homicides

#Use prop.test function on the unsolved and total homicides from baltimore
balt_proptest = 
  prop.test(balt_unsolved, balt_total) |> 
  
  #Tidy the propotional test output
  broom::tidy()

#Extract the proportion and confidence interval from balt_proptes
balt_est = balt_proptest$estimate
balt_ci_low = balt_proptest$conf.low
balt_ci_high = balt_proptest$conf.high

```
* _Proportion of Homicides Unsolved in Baltimore, MD_: `r balt_est`
* _95%CI_: (`r balt_ci_low`, `r balt_ci_high`)

__Now Run `prop.test` on each city...__

...in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

```{r}
#Function that runs prop.test for each city
run_prop_test = function(x) {
  result = 
    prop.test(x$num_unsolved, x$total_homicides) |> 
    broom::tidy()
  
  
  tibble(city_state = x$city_state,
         est = result$estimate,
         ci_low = result$conf.low,
         ci_high = result$conf.high)
}

#Create a list to iterate over 
homicide_list = split(sum_homicides, 1:nrow(sum_homicides))

#Create empty list to fill with 
prop_list = vector("list",51)
for (i in 1:51) {
  prop_list[[i]] = run_prop_test(homicide_list[[i]])
}

#Convert list into dataframe
prop_df = bind_rows(prop_list)

head(prop_df, 10)
```

__Create a plot__

...that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.


```{r}
  prop_df |> 
  #arrange by estimate ascending
  arrange(est) |> 
  #redfine city_state to factors and ordered based on their arrangement by est
  mutate(city_state = factor(city_state, levels = city_state)) |> 
  ggplot(aes(x = city_state, y = est)) + 
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high)) +
  #make xaxis label more clear
  coord_flip()
```


# Problem 2

##Create a tidy dataframe... 

...containing data from all participants, including the subject ID, arm, and observations over time:

__Start with a dataframe containing all file names;__

```{r}
#Retrieve directory names to iterate over (List)
file_names = list.files("./data", pattern = "^(con|exp)", full.names = TRUE)

#Retrieve subject name from the file names (List)
sub_names = substr(file_names, 8,13)

#Iterate all file names and read_csv using map
subject_data_list = map(file_names,read_csv, show_col_types = FALSE)

#Convert list to dataframe, add subject id + arm
subject_data = 
  bind_rows(subject_data_list) |> 
  mutate(subject_id = substr(sub_names,5,6)) |> 
  mutate(arm = substr(sub_names, 1,3)) |> 
  select(subject_id, arm, everything()) |> 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "value")
  )

```

